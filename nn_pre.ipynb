{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import numpy as np\n",
    "import scipy\n",
    "import skimage\n",
    "import ants\n",
    "# downscale = 4\n",
    "# img_path = \"/storage/valis_reg/BFIW_Block/msrcr\"\n",
    "# img_paths = [os.path.join(img_path, img) for img in os.listdir(img_path)]\n",
    "# save_paths = [os.path.join(\"/storage/valis_reg/BFIW_Block_low_res/msrcr\", img) for img in os.listdir(img_path)]\n",
    "\n",
    "\n",
    "# def store_downscaled_image(img_path, save_path):\n",
    "#     img = cv2.imread(img_path)\n",
    "#     img = cv2.resize(img, (img.shape[1]//downscale, img.shape[0]//downscale))\n",
    "#     cv2.imwrite(save_path, img)\n",
    "\n",
    "# _ = Parallel(n_jobs=16)(delayed(store_downscaled_image)(img_path, save_path) for img_path, save_path in tqdm(zip(img_paths, save_paths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def get_ksize(sigma):\n",
    "    # opencv calculates ksize from sigma as\n",
    "    # sigma = 0.3*((ksize-1)*0.5 - 1) + 0.8\n",
    "    # then ksize from sigma is\n",
    "    # ksize = ((sigma - 0.8)/0.15) + 2.0\n",
    "\n",
    "    return int(((sigma - 0.8)/0.15) + 2.0)\n",
    "\n",
    "def get_gaussian_blur(img, ksize=0, sigma=5):\n",
    "    # if ksize == 0, then compute ksize from sigma\n",
    "    if ksize == 0:\n",
    "        ksize = get_ksize(sigma)\n",
    "\n",
    "    # Gaussian 2D-kernel can be seperable into 2-orthogonal vectors\n",
    "    # then compute full kernel by taking outer product or simply mul(V, V.T)\n",
    "    sep_k = cv2.getGaussianKernel(ksize, sigma)\n",
    "\n",
    "    # if ksize >= 11, then convolution is computed by applying fourier transform\n",
    "    return cv2.filter2D(img, -1, np.outer(sep_k, sep_k))\n",
    "\n",
    "def ssr(img, sigma):\n",
    "    # Single-scale retinex of an image\n",
    "    # SSR(x, y) = log(I(x, y)) - log(I(x, y)*F(x, y))\n",
    "    # F = surrounding function, here Gaussian\n",
    "\n",
    "    return np.log10(img) - np.log10(get_gaussian_blur(img, ksize=0, sigma=sigma) + 1.0)\n",
    "\n",
    "def msr(img, sigma_scales=[15, 80, 250]):\n",
    "    # Multi-scale retinex of an image\n",
    "    # MSR(x,y) = sum(weight[i]*SSR(x,y, scale[i])), i = {1..n} scales\n",
    "\n",
    "    msr = np.zeros(img.shape)\n",
    "    # for each sigma scale compute SSR\n",
    "    for sigma in sigma_scales:\n",
    "        msr += ssr(img, sigma)\n",
    "\n",
    "    # divide MSR by weights of each scale\n",
    "    # here we use equal weights\n",
    "    msr = msr / len(sigma_scales)\n",
    "\n",
    "    # computed MSR could be in range [-k, +l], k and l could be any real value\n",
    "    # so normalize the MSR image values in range [0, 255]\n",
    "    msr = cv2.normalize(msr, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8UC3)\n",
    "\n",
    "    return msr\n",
    "\n",
    "def color_balance(img, low_per, high_per):\n",
    "    '''Contrast stretch img by histogram equilization with black and white cap'''\n",
    "\n",
    "    tot_pix = img.shape[1] * img.shape[0]\n",
    "    # no.of pixels to black-out and white-out\n",
    "    low_count = tot_pix * low_per / 100\n",
    "    high_count = tot_pix * (100 - high_per) / 100\n",
    "\n",
    "    # channels of image\n",
    "    ch_list = []\n",
    "    if len(img.shape) == 2:\n",
    "        ch_list = [img]\n",
    "    else:\n",
    "        ch_list = cv2.split(img)\n",
    "\n",
    "    cs_img = []\n",
    "    # for each channel, apply contrast-stretch\n",
    "    for i in range(len(ch_list)):\n",
    "        ch = ch_list[i]\n",
    "        # cummulative histogram sum of channel\n",
    "        cum_hist_sum = np.cumsum(cv2.calcHist([ch], [0], None, [256], (0, 256)))\n",
    "\n",
    "        # find indices for blacking and whiting out pixels\n",
    "        li, hi = np.searchsorted(cum_hist_sum, (low_count, high_count))\n",
    "        if (li == hi):\n",
    "            cs_img.append(ch)\n",
    "            continue\n",
    "        # lut with min-max normalization for [0-255] bins\n",
    "        lut = np.array([0 if i < li\n",
    "                        else (255 if i > hi else round((i - li) / (hi - li) * 255))\n",
    "                        for i in np.arange(0, 256)], dtype = 'uint8')\n",
    "        # constrast-stretch channel\n",
    "        cs_ch = cv2.LUT(ch, lut)\n",
    "        cs_img.append(cs_ch)\n",
    "\n",
    "    if len(cs_img) == 1:\n",
    "        return np.squeeze(cs_img)\n",
    "    elif len(cs_img) > 1:\n",
    "        return cv2.merge(cs_img)\n",
    "    return None\n",
    "\n",
    "def msrcr(img, sigma_scales=[15, 80, 250], alpha=125, beta=46, G=192, b=-30, low_per=1, high_per=3):\n",
    "    # Multi-scale retinex with Color Restoration\n",
    "    # MSRCR(x,y) = G * [MSR(x,y)*CRF(x,y) - b], G=gain and b=offset\n",
    "    # CRF(x,y) = beta*[log(alpha*I(x,y) - log(I'(x,y))]\n",
    "    # I'(x,y) = sum(Ic(x,y)), c={0...k-1}, k=no.of channels\n",
    "\n",
    "    img = img.astype(np.float64) + 1.0\n",
    "    # Multi-scale retinex and don't normalize the output\n",
    "    msr_img = msr(img, sigma_scales)\n",
    "    # Color-restoration function\n",
    "    crf = beta * (np.log10(alpha * img) - np.log10(np.sum(img, axis=2, keepdims=True)))\n",
    "    # MSRCR\n",
    "    msrcr_ = G * (msr_img*crf - b)\n",
    "    # normalize MSRCR\n",
    "    msrcr_ = cv2.normalize(msrcr_, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8UC3) # type: ignore\n",
    "    # color balance the final MSRCR to flat the histogram distribution with tails on both sides\n",
    "    msrcr_ = color_balance(msrcr_, low_per, high_per)\n",
    "\n",
    "    return msrcr_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BFIWSlide:\n",
    "    def __init__(self, slide_path, key=None, is_ref=False):\n",
    "        self.slide_path = slide_path\n",
    "        self.key = key\n",
    "        self.img = cv2.imread(slide_path)\n",
    "        self.img = cv2.cvtColor(self.img, cv2.COLOR_BGR2RGB)\n",
    "        self.msr_img = None\n",
    "        self.msr_img_gray = None\n",
    "        self.mask = None\n",
    "        self.is_ref = is_ref\n",
    "        self.apply_msrcr()\n",
    "        self.get_mask()\n",
    "        self.apply_mask(self.mask)\n",
    "\n",
    "    def apply_msrcr(self):\n",
    "        self.msr_img = msrcr(self.img)\n",
    "        self.msr_img_gray = cv2.cvtColor(self.msr_img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    def apply_mask(self, mask):\n",
    "        self.temp_img = (np.ones_like(self.img) * 255).astype(np.uint8)\n",
    "        self.temp_img[mask == 1] = self.img[mask == 1]\n",
    "        self.img = self.temp_img\n",
    "        self.temp_img = (np.ones_like(self.img) * 255).astype(np.uint8)\n",
    "        self.temp_img[mask == 1] = self.msr_img[mask == 1]\n",
    "        self.msr_img = self.temp_img\n",
    "\n",
    "    def get_mask(self):\n",
    "        if self.msr_img_gray is None:\n",
    "            self.apply_msrcr()\n",
    "        sample_ants = ants.from_numpy(self.msr_img_gray)\n",
    "        self.mask = sample_ants.get_mask(cleanup=4).numpy().astype(np.uint8) # type: ignore\n",
    "        # return self.mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BFIWReg:\n",
    "    def __init__(self, src_dir, dest_dir, ref_idx) -> None:\n",
    "        self.src_dir = src_dir\n",
    "        imgs = os.listdir(self.src_dir)\n",
    "        regex = re.compile(r\".*-SE_(\\d+)_original.jpg\")\n",
    "        imgs = sorted(imgs, key=lambda x: int(regex.match(x).group(1)))\n",
    "        imgs_ordered = {}\n",
    "        for img in imgs:\n",
    "            section_num = int(regex.match(img).group(1))\n",
    "            section_id = str(section_num)\n",
    "            section_id_digits = len(section_id)\n",
    "            if section_id_digits <4:\n",
    "                section_id = '0'*(4-section_id_digits) + str(section_num)\n",
    "            imgs_ordered[section_id] = os.path.join(self.src_dir, img)\n",
    "        self.imgs = imgs_ordered\n",
    "        self.ref_slide = BFIWSlide(self.imgs[ref_idx], key=ref_idx, is_ref=True)\n",
    "        self.slides = {key: BFIWSlide(val, key=key) for key, val in self.imgs.items() if key != ref_idx}\n",
    "        self.slides[ref_idx] = self.ref_slide"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
