{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b5105e1-9d58-4954-9255-1e60beb72e8c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "max() iterable argument is empty",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 61\u001b[0m\n\u001b[1;32m     59\u001b[0m input_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../keerthi_data/BFIW_original/\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Replace with your input folder path\u001b[39;00m\n\u001b[1;32m     60\u001b[0m output_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./cropped_imgs_new/\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Replace with your output folder path\u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m \u001b[43mprocess_BFI_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_folder\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[18], line 48\u001b[0m, in \u001b[0;36mprocess_BFI_images\u001b[0;34m(input_folder, output_folder)\u001b[0m\n\u001b[1;32m     46\u001b[0m contours, _ \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mfindContours(thresh1, cv2\u001b[38;5;241m.\u001b[39mRETR_EXTERNAL, cv2\u001b[38;5;241m.\u001b[39mCHAIN_APPROX_SIMPLE)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Select contours with fewer than `max_pixels`\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m valid_contours \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcontour\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcontour\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcontours\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontourArea\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontour\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Get the bounding rectangle of the brain contour\u001b[39;00m\n\u001b[1;32m     51\u001b[0m x1, y1, w1, h1 \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mboundingRect(valid_contours)\n",
      "\u001b[0;31mValueError\u001b[0m: max() iterable argument is empty"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import valis\n",
    "\n",
    "thresh = 130\n",
    "\n",
    "def process_BFI_images(input_folder, output_folder):\n",
    "    \"\"\"Processes all images in the input folder and saves the results to the output folder.\n",
    "\n",
    "    Args:\n",
    "        input_folder (str): The path to the input folder containing the images.\n",
    "        output_folder (str): The path to the output folder where the Â  \n",
    " processed images will be saved.\n",
    "    \"\"\"\n",
    "\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    filename = 'B_213-ST_BFIW-SE_215_original.jpg' \n",
    "    #for filename in os.listdir(input_folder):\n",
    "    if filename.endswith(('.jpg')):\n",
    "        image_path = os.path.join(input_folder, filename)\n",
    "\n",
    "        output_path = os.path.join(output_folder, filename)\n",
    "\n",
    "            # Load the image using Pillow\n",
    "        with Image.open(image_path) as img:\n",
    "                # Perform your image processing operations here\n",
    "                # For example, you could resize, rotate, apply filters, etc.\n",
    "                # Replace this with your specific processing logic\n",
    "                img1 = np.array(img.convert('RGB'))\n",
    "                gray=img1[:,:,1]\n",
    "                bw = cv2.threshold(gray, thresh, 255, cv2.THRESH_BINARY)[1]\n",
    "                contours, _ = cv2.findContours(bw, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "                largest_contour = max(contours, key=cv2.contourArea)\n",
    "                # Get the bounding rectangle of the brain contour\n",
    "                x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "\n",
    "                # Crop the image using the bounding rectangle\n",
    "                cropped_image = img1[y:y+h, x:x+w]\n",
    "                img_new = valis.preprocessing.standardize_colorfulness(cropped_image, c=0.2, h=0)\n",
    "                _, thresh1 = cv2.threshold(img_new[:,:,1], 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "                # Find contours in the thresholded image\n",
    "                contours, _ = cv2.findContours(thresh1, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "                # Select contours with fewer than `max_pixels`\n",
    "                valid_contours = [contour for contour in contours if cv2.contourArea(contour) ]\n",
    "\n",
    "                # Get the bounding rectangle of the brain contour\n",
    "                x1, y1, w1, h1 = cv2.boundingRect(valid_contours)\n",
    "                cropped_image_n = img_new[y1:y1+h1, x1:x1+w1]\n",
    "                processed_img = Image.fromarray(np.uint8(cropped_image_n))\n",
    "\n",
    "                # Save the processed image\n",
    "                processed_img.save(output_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_folder = \"../keerthi_data/BFIW_original/\"  # Replace with your input folder path\n",
    "    output_folder = \"./cropped_imgs_new/\"  # Replace with your output folder path\n",
    "    process_BFI_images(input_folder, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb07e55b-ad45-464b-ab23-b48dff8d38b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export OPENBLAS_NUM_THREADS=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4dbfcf-a24d-4e2f-a05d-f4998e2727c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
